
# VERSION v16: GPT-3.5 –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ª–æ–≤–∞, GPT-4 —Ç–æ–ª—å–∫–æ –Ω–∞ low probability. –í–æ–ø—Ä–æ—Å—ã ‚Äî —á–µ—Ä–µ–∑ –ø—Ä–∞–≤–∏–ª–æ.

USE_CORRECTOR = True  # –û—Ç–∫–ª—é—á–∏—Ç—å, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω—ã –ø—Ä–∞–≤–∫–∏ —Å–ª–æ–≤


import argparse

# === –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ===
parser = argparse.ArgumentParser(
    description="""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  python3 transcribe_with_diarization_v20.py path/to/file.mp3 --lang en --gpt gpt-4 --probability-threshold 0.95

–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —è–∑—ã–∫: ru, –º–æ–¥–µ–ª—å: gpt-3.5-turbo, –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: 0.55
""",
    formatter_class=argparse.RawDescriptionHelpFormatter
)

parser.add_argument("audio_file", help="–ü—É—Ç—å –∫ .mp3 –∏–ª–∏ .wav —Ñ–∞–π–ª—É")
parser.add_argument("--lang", choices=["ru", "en"], default="ru", help="–Ø–∑—ã–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (ru/en)")
parser.add_argument("--gpt", choices=["gpt-3.5-turbo", "gpt-4"], default="gpt-3.5-turbo", help="–ú–æ–¥–µ–ª—å GPT")
parser.add_argument("--probability-threshold", type=float, default=0.55,
                    help="–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ GPT-4 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.55)")
parser.add_argument("--skip-whisper", action="store_true", help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–∞–ø Whisper, –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π JSON")

args = parser.parse_args()

PROBABILITY_THRESHOLD = args.probability_threshold

audio_file = args.audio_file
LANGUAGE = args.lang
GPT_MODEL = args.gpt

import openai
system_prompt_ru = "–¢—ã ‚Äî –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤—â–∏–∫ —Ç–µ–∫—Å—Ç–∞. –ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω–∏ —Å—Ç–∏–ª—å, –Ω–µ —Å–æ–∫—Ä–∞—â–∞–π, –Ω–µ —É–±–∏—Ä–∞–π –ø—Ä–µ–¥–ª–æ–≥–∏. –ù–µ –∏—Å–ø—Ä–∞–≤–ª—è–π —Å–ª–µ–Ω–≥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–∫–æ—Å—Ç—ã', '—Å–∏–Ω–∫', '–±–∞–±–∫–∏'). –û—Ç–≤–µ—Ç—å —Å–ø–∏—Å–∫–æ–º JSON –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–ª—è–º–∏ 'speaker' –∏ 'text'."
system_prompt_en = "You are a text corrector. Fix recognition errors, preserve the style, do not shorten or remove prepositions. Do not correct slang (e.g., 'costs', 'sync', 'bucks'). Return a list of JSON objects with fields 'speaker' and 'text'."
import json

def correct_text_with_gpt(text, speaker_label, use_gpt4=False):
    model = "gpt-4" if use_gpt4 else GPT_MODEL
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt_ru if LANGUAGE == "ru" else system_prompt_en},
                {"role": "user", "content": f'{{"speaker": "{speaker_label}", "text": "{text}"}}'}
            ],
            max_tokens=500
        )
        cleaned = response.choices[0].message.content.strip()
        data = json.loads(cleaned)
        return data.get("speaker", speaker_label), data.get("text", text)
    except Exception as e:
        print(f"‚ö†Ô∏è GPT error: {e}")
        return speaker_label, text


# MASTER SCRIPT v7: diarize + transcribe with roles using Whisper (medium)


import ssl
ssl._create_default_https_context = ssl._create_unverified_context

import whisper
from resemblyzer import preprocess_wav, VoiceEncoder
from resemblyzer.hparams import sampling_rate
from sklearn.cluster import KMeans
from docx import Document
from docx.shared import Pt, RGBColor
from datetime import timedelta, datetime
import numpy as np
import os, sys, json
import openai
system_prompt_ru = "–¢—ã ‚Äî –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤—â–∏–∫ —Ç–µ–∫—Å—Ç–∞. –ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω–∏ —Å—Ç–∏–ª—å, –Ω–µ —Å–æ–∫—Ä–∞—â–∞–π, –Ω–µ —É–±–∏—Ä–∞–π –ø—Ä–µ–¥–ª–æ–≥–∏. –ù–µ –∏—Å–ø—Ä–∞–≤–ª—è–π —Å–ª–µ–Ω–≥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–∫–æ—Å—Ç—ã', '—Å–∏–Ω–∫', '–±–∞–±–∫–∏'). –û—Ç–≤–µ—Ç—å —Å–ø–∏—Å–∫–æ–º JSON –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–ª—è–º–∏ 'speaker' –∏ 'text'."
system_prompt_en = "You are a text corrector. Fix recognition errors, preserve the style, do not shorten or remove prepositions. Do not correct slang (e.g., 'costs', 'sync', 'bucks'). Return a list of JSON objects with fields 'speaker' and 'text'."

# === GPT Pricing model ===
pricing = {
    "gpt-3.5-turbo": {"prompt": 0.0005, "completion": 0.0015},
    "gpt-4":         {"prompt": 0.03,   "completion": 0.06}
}


# === Step 1: Get audio file ===
if len(sys.argv) > 1:
    audio_file = sys.argv[1]
else:
    audio_file = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ .mp3 –∏–ª–∏ .wav —Ñ–∞–π–ª—É: ").strip()

if not os.path.exists(audio_file):
    print("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    sys.exit(1)

# === Load OpenAI API key ===
api_key_path = os.path.join(os.path.dirname(audio_file), "openai_api_key.txt")
if not os.path.exists(api_key_path):
    api_key_path = os.path.expanduser("~/.openai_api_key")
if os.path.exists(api_key_path):
    with open(api_key_path, "r") as f:
        openai.api_key = f.read().strip()
else:
    print("‚ùå –§–∞–π–ª —Å API –∫–ª—é—á–æ–º OpenAI –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    sys.exit(1)

# === Step 2: Diarization ===
print("üîä –í—ã–ø–æ–ª–Ω—è–µ–º –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é...")
wav = preprocess_wav(audio_file)
encoder = VoiceEncoder()
_, embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16)

kmeans = KMeans(n_clusters=2, random_state=0).fit(embeds)
labels = kmeans.labels_

intervals = []
for i, label in enumerate(labels):
    start = wav_splits[i].start
    end = wav_splits[i].stop if i + 1 < len(wav_splits) else len(wav)
    intervals.append({
        "start": round(start / sampling_rate, 2),
        "end": round(end / sampling_rate, 2),
        "speaker": int(label)
    })

# === Save diarization to JSON ===
base_name = os.path.splitext(os.path.basename(audio_file))[0]
timestamp = datetime.now().strftime("%Y%m%d_%H%M")
json_path = f"{base_name}_diarization_{timestamp}.json"
with open(json_path, "w") as f:
    json.dump(intervals, f, indent=2)
print(f"‚úÖ –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {json_path}")


whisper_result_path = f"{os.path.splitext(audio_file)[0]}_whisper.json"

# === Step 3: Whisper Transcription ===
if args.skip_whisper and os.path.exists(whisper_result_path):
    print("‚è© –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Whisper, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç...")
    with open(whisper_result_path, "r", encoding="utf-8") as f:
        result = json.load(f)
else:
    print("üß† –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å (Whisper medium)...")
    model = whisper.load_model("medium")
    result = model.transcribe(audio_file, language=LANGUAGE, word_timestamps=True)
    with open(whisper_result_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)


# === Step 4: Match speaker ===
def get_best_matching_speaker(start_time, end_time):
    durations = {0: 0.0, 1: 0.0}
    for entry in intervals:
        overlap_start = max(start_time, entry["start"])
        overlap_end = min(end_time, entry["end"])
        overlap = max(0.0, overlap_end - overlap_start)
        durations[entry["speaker"]] += overlap
    return 0 if durations[0] > durations[1] else 1


with open(whisper_result_path, "w", encoding="utf-8") as f:
    json.dump(result, f, ensure_ascii=False, indent=2)


if os.path.exists(whisper_result_path):
    with open(whisper_result_path, "r", encoding="utf-8") as f:
        result = json.load(f)
else:
    result = model.transcribe(...)


# === GPT-3.5 Question Enhancer ===
gpt35_requests = 0
gpt35_tokens_prompt = 0
gpt35_tokens_completion = 0
gpt4_requests = 0
gpt4_tokens_prompt = 0
gpt4_tokens_completion = 0
correction_log = []

# def enhance_questions_with_gpt(text, speaker_label):
#     global gpt35_requests, gpt35_tokens_prompt, gpt35_tokens_completion, correction_log
#     try:
#         payload = json.dumps({"speaker": speaker_label, "text": text}, ensure_ascii=False)
#         response = openai.ChatCompletion.create(
#             model="gpt-3.5-turbo",
#             messages=[
#                 {"role": "system", "content": """–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä. –î–æ–±–∞–≤—å –≤ —Ç–µ–∫—Å—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞–∫–∏ –≤–æ–ø—Ä–æ—Å–∞, –µ—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å –æ–¥–Ω–æ–≥–æ –∏–∑ —Å–ª–µ–¥—É—é—â–∏—Ö —Å–ª–æ–≤: —á—Ç–æ, –∫–∞–∫, –≥–¥–µ, –ø–æ—á–µ–º—É, –∫–æ–≥–¥–∞, –∑–∞—á–µ–º, –∫—Ç–æ, –∫–∞–∫–æ–π, –∫–∞–∫–∞—è, –∫–∞–∫–∏–µ, –∫–∞–∫–æ–≤, –∫–∞–∫–æ–≤–æ, –æ—Ç–∫—É–¥–∞, —Å–∫–æ–ª—å–∫–æ, —á–µ–º, —á–µ–≥–æ, —á–µ–º—É, —á—å—ë, —á—å—è, —á—å–∏, —á–µ–π. –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è–π –∑–Ω–∞–∫ –≤–æ–ø—Ä–æ—Å–∞, –µ—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Ñ—Ä–∞–∑: –Ω—É –∫–∞–∫, –Ω—É —á—Ç–æ, –Ω—É –≥–¥–µ, –Ω—É –ø–æ—á–µ–º—É, –∞ –∫–∞–∫, –∞ —á—Ç–æ, –∞ –≥–¥–µ, –∞ –ø–æ—á–µ–º—É, –∞ –∑–∞—á–µ–º, –∞ –∫—Ç–æ –∏ —Ç.–ø. –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è–π –∑–Ω–∞–∫ –≤–æ–ø—Ä–æ—Å–∞, –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —á–∞—Å—Ç–∏—Ü–∞ '–ª–∏' –ø–æ—Å–ª–µ –ø–æ–¥–ª–µ–∂–∞—â–µ–≥–æ. –ù–µ –∏–∑–º–µ–Ω—è–π —Å—Ç–∏–ª—å, –Ω–µ —Å–æ–∫—Ä–∞—â–∞–π. –°–æ—Ö—Ä–∞–Ω–∏ —Å–ª–µ–Ω–≥ –∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è. –í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏: 'speaker' –∏ 'text'."""},
#                 {"role": "user", "content": payload}
#             ],
#             max_tokens=500
#         )
#         usage = response.usage
#         gpt35_requests += 1
#         gpt35_tokens_prompt += usage.prompt_tokens
#         gpt35_tokens_completion += usage.completion_tokens
#         cleaned = json.loads(response.choices[0].message.content.strip())
#         correction_log.append({
#             "original": {"speaker": speaker_label, "text": text},
#             "corrected": cleaned
#         })
#         return cleaned.get("speaker", speaker_label), cleaned.get("text", text)
#     except Exception as e:
#         print(f"‚ö†Ô∏è GPT –æ—à–∏–±–∫–∞: {e}")
#         return speaker_label, text


def enhance_questions_with_gpt(text, speaker=None):
    question_words = {
        "—á—Ç–æ", "–∫–∞–∫", "–≥–¥–µ", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º", "–∫–æ–≥–¥–∞", "–∫–∞–∫–æ–π", "–∫–∞–∫–∞—è", "–∫–∞–∫–∏–µ", "–∫–∞–∫–æ–≤", "–æ—Ç–∫—É–¥–∞",
        "—Å–∫–æ–ª—å–∫–æ", "—á–µ–≥–æ", "—á–µ–º", "—á—å–µ", "—á—å—è", "—á—å–∏", "–∫–æ–º—É", "–∫–æ–≥–æ", "–∫—É–¥–∞", "–ø–æ—á–µ–º", "–ø–æ-—á–µ–º—É",
        "–Ω—É —á—Ç–æ", "–Ω—É –∫–∞–∫", "–Ω—É –≥–¥–µ", "–∞ —á—Ç–æ", "–∞ –∫–∞–∫", "–∞ –≥–¥–µ", "–∞ –ø–æ—á–µ–º—É", "–∞ –∑–∞—á–µ–º", "–∞ –∫–æ–≥–¥–∞"
    }

    cleaned_text = text.strip()
    text_lower = cleaned_text.lower()

    if not text_lower.endswith("?"):
        for w in question_words:
            if text_lower.startswith(w + " ") or text_lower.startswith(w + ","):
                cleaned_text += "?"
                break

    return speaker, cleaned_text


# === Step 5: Build Word Document ===
print("üìÑ –§–æ—Ä–º–∏—Ä—É–µ–º Word-–¥–æ–∫—É–º–µ–Ω—Ç...")
doc = Document()
doc.add_heading(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Å —Ä–æ–ª—è–º–∏ ‚Äì {audio_file}", level=1)


for seg in result["segments"]:
    
    if not seg.get("text", "").strip():
        continue

    start = round(seg["start"], 2)
    end = round(seg["end"], 2)
    speaker_id = get_best_matching_speaker(start, end)
    speaker = "–ò–Ω—Ç–µ—Ä–≤—å—é–µ—Ä" if speaker_id == 0 else "–ö–∞–Ω–¥–∏–¥–∞—Ç"

    timecode = str(timedelta(seconds=int(start)))
    doc.add_paragraph(f"[{timecode}]")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ probability

    has_low_probability = False
    words = seg.get("words", [])

    if words:
        low_conf = [w for w in words if w.get("probability", 1.0) < PROBABILITY_THRESHOLD]
        has_low_probability = len(low_conf) > 0

    else:
        print(f"‚ö†Ô∏è –ù–µ—Ç word-level probability –≤ —Å–µ–≥–º–µ–Ω—Ç–µ: '{seg['text']}'")
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ ‚Äî –ø–æ avg_logprob
        if seg.get("avg_logprob", 0) < -1.0:
            has_low_probability = True


    if has_low_probability:
        try:
            payload = json.dumps({"speaker": speaker, "text": seg["text"].strip()}, ensure_ascii=False)
            model_to_use = GPT_MODEL  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å

            response = openai.ChatCompletion.create(
                model=model_to_use,
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä. –ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ –≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ. –ù–µ –º–µ–Ω—è–π —Å—Ç–∏–ª—å, –Ω–µ —Å–æ–∫—Ä–∞—â–∞–π –∏ –Ω–µ –∑–∞–º–µ–Ω—è–π —Å–ª–µ–Ω–≥. –í–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏: 'speaker' –∏ 'text'."
                    },
                    {"role": "user", "content": payload}
                ],
                max_tokens=500
            )

            usage = response.usage
            if model_to_use == "gpt-4":
                gpt4_requests += 1
                gpt4_tokens_prompt += usage.prompt_tokens
                gpt4_tokens_completion += usage.completion_tokens
            else:
                gpt35_requests += 1
                gpt35_tokens_prompt += usage.prompt_tokens
                gpt35_tokens_completion += usage.completion_tokens

            cleaned = json.loads(response.choices[0].message.content.strip())
            final_speaker = cleaned.get("speaker", speaker)
            enhanced_text = cleaned.get("text", seg["text"].strip())
            correction_log.append({
                "original": {"speaker": speaker, "text": seg["text"].strip()},
                "corrected": cleaned,
                "used_model": model_to_use
            })
        except Exception as e:
            print(f"‚ö†Ô∏è GPT –æ—à–∏–±–∫–∞: {e}")
            final_speaker, enhanced_text = enhance_questions_with_gpt(seg["text"], speaker)
    else:
        final_speaker, enhanced_text = enhance_questions_with_gpt(seg["text"], speaker)


    p = doc.add_paragraph()
    run = p.add_run(f"{final_speaker}: ")
    run.bold = True
    run.font.size = Pt(11)
    run_text = p.add_run(enhanced_text)
    run_text.font.size = Pt(11)

    if final_speaker == "–ò–Ω—Ç–µ—Ä–≤—å—é–µ—Ä":
        run_text.font.color.rgb = RGBColor(0, 128, 0)
    if enhanced_text.strip().endswith("?"):
        run_text.font.color.rgb = RGBColor(128, 0, 128)


# === Save output files ===
doc_timestamp = datetime.now().strftime("%Y%m%d_%H%M")
output_file = f"{os.path.splitext(audio_file)[0]}_with_roles_{doc_timestamp}.docx"
doc.save(output_file)
print(f"‚úÖ –ì–æ—Ç–æ–≤–æ: {output_file}")

# === Save GPT stats ===
stats_path = os.path.splitext(audio_file)[0] + f"_gpt_stats_{doc_timestamp}.txt"
with open(stats_path, "w") as f:
    f.write(f"üéØ –ü–æ—Ä–æ–≥ probability (probability): {PROBABILITY_THRESHOLD}\n")
    f.write(f"üí¨ –ó–∞–ø—Ä–æ—Å–æ–≤ GPT-3.5: {gpt35_requests}\n")
    f.write(f"üî¢ Prompt —Ç–æ–∫–µ–Ω–æ–≤ GPT-3.5: {gpt35_tokens_prompt}\n")
    f.write(f"üî¢ Completion —Ç–æ–∫–µ–Ω–æ–≤ GPT-3.5: {gpt35_tokens_completion}\n")
    f.write(f"üí¨ –ó–∞–ø—Ä–æ—Å–æ–≤ GPT-4: {gpt4_requests}\n")
    f.write(f"üî¢ Prompt —Ç–æ–∫–µ–Ω–æ–≤ GPT-4: {gpt4_tokens_prompt}\n")
    f.write(f"üî¢ Completion —Ç–æ–∫–µ–Ω–æ–≤ GPT-4: {gpt4_tokens_completion}\n")
    cost_35 = (gpt35_tokens_prompt * pricing['gpt-3.5-turbo']['prompt'] + gpt35_tokens_completion * pricing['gpt-3.5-turbo']['completion']) / 1000
    cost_4 = (gpt4_tokens_prompt * pricing['gpt-4']['prompt'] + gpt4_tokens_completion * pricing['gpt-4']['completion']) / 1000
    total = cost_35 + cost_4
    f.write(f"üí∞ –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏:\n")
    f.write(f"GPT-3.5: ~$ {cost_35:.4f}\n")
    f.write(f"GPT-4:   ~$ {cost_4:.4f}\n")
    f.write(f"–ò–¢–û–ì–û:  ~$ {total:.4f}\n")
print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ GPT —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {stats_path}")

# === Save corrections log ===
log_path = os.path.splitext(audio_file)[0] + f"_gpt_corrections_log_{doc_timestamp}.json"
with open(log_path, "w", encoding="utf-8") as f:
    json.dump(correction_log, f, indent=2, ensure_ascii=False)
print(f"üìÅ –õ–æ–≥ –ø—Ä–∞–≤–æ–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {log_path}")



# –ü—Ä–∏–º–µ—Ä –≤—ã–∑–æ–≤–∞ –≤–Ω—É—Ç—Ä–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤:
if USE_CORRECTOR:
    new_speaker, cleaned_text = correct_text_with_gpt(seg["text"].strip(), speaker, has_low_probability)
else:
    new_speaker, cleaned_text = speaker, seg["text"].strip()
